{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "49ea1168",
      "metadata": {},
      "source": [
        "### Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba515587",
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install google-analytics-data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fe8cacc",
      "metadata": {},
      "source": [
        "### Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e768e6f",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score, cross_validate, StratifiedKFold\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa480be2",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Set working directory - CHANGE THIS TO YOUR PATH\n",
        "os.chdir(\"/anonymized_path/sakshikumar/Documents/UCD/04. SP 2025/464 Practicum/KWSM finale/FINAL FILES\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68b6e0f1",
      "metadata": {},
      "source": [
        "### Fetch GA4 API data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1197947",
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.analytics.data_v1beta import BetaAnalyticsDataClient\n",
        "from google.analytics.data_v1beta.types import DateRange, Dimension, Metric, RunReportRequest\n",
        "from google.oauth2 import service_account\n",
        "\n",
        "creds = service_account.Credentials.from_service_account_file(\"credentials.json\")\n",
        "client = BetaAnalyticsDataClient(credentials=creds)\n",
        "\n",
        "property_id = \"359323282\"\n",
        "\n",
        "request = RunReportRequest(\n",
        "    property=f\"properties/{property_id}\",\n",
        "    dimensions=[\n",
        "        Dimension(name=\"pagePath\"),\n",
        "        Dimension(name=\"eventName\")\n",
        "    ],\n",
        "    metrics=[Metric(name=\"eventCount\")],\n",
        "    date_ranges=[DateRange(start_date=\"2024-05-10\", end_date=\"today\")],\n",
        ")\n",
        "\n",
        "response = client.run_report(request)\n",
        "\n",
        "rows = []\n",
        "for row in response.rows:\n",
        "    rows.append([dim.value for dim in row.dimension_values] + [metric.value for metric in row.metric_values])\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(rows, columns=[\"pagePath\", \"eventName\", \"eventCount\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90fa5641",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "794355c3",
      "metadata": {},
      "outputs": [],
      "source": [
        "list_df = pd.DataFrame(df['pagePath'].unique())\n",
        "list_df.to_csv('pagePath.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3e734e4",
      "metadata": {},
      "source": [
        "### Loading Model 2 Dataset Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc92ce4d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Load and prepare your dataset\n",
        "attempt2_df = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Drop duplicates\n",
        "attempt2_df = attempt2_df.drop_duplicates()\n",
        "\n",
        "# 2. Define new target: High Engagement (over 30 seconds per session)\n",
        "# attempt2_df['High_Engagement'] = (attempt2_df['Average engagement time per session'] > 30).astype(int)\n",
        "attempt2_df['Low_Bounce'] = (attempt2_df['Bounce rate'] < 0.3).astype(int)\n",
        "\n",
        "print(\"Low Bounce distribution:\\n\", attempt2_df['Low_Bounce'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e27765a",
      "metadata": {},
      "outputs": [],
      "source": [
        "attempt2_df['Bounce rate'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c379185",
      "metadata": {},
      "source": [
        "### Preparing variables for Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16ae5c4b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Prepare Features\n",
        "drop_cols = ['URL', 'Keyword', 'pagePath'] if 'pagePath' in attempt2_df.columns else ['URL', 'Keyword']\n",
        "X = attempt2_df.drop(columns=drop_cols + ['Low_Bounce'])\n",
        "y = attempt2_df['Low_Bounce']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "002120ee",
      "metadata": {},
      "source": [
        "#### Drawing Correlation Matrix to check for Multicolinearity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0dc372da",
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(X.corr(), cmap='coolwarm', center=0)\n",
        "plt.title('Feature Correlation Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c8a47fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Compute correlation matrix\n",
        "corr_matrix = X.corr().abs()\n",
        "\n",
        "# 2. Select upper triangle of correlation matrix\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "\n",
        "# 3. Find features with correlation greater than threshold\n",
        "threshold = 0.85\n",
        "to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
        "\n",
        "print(f\"\u2705 Features to drop due to high correlation (> {threshold}):\")\n",
        "print(to_drop)\n",
        "\n",
        "# 4. Drop them\n",
        "X_reduced = X.drop(columns=to_drop)\n",
        "\n",
        "print(f\"\\nShape before dropping: {X.shape}\")\n",
        "print(f\"Shape after dropping: {X_reduced.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c49a26da",
      "metadata": {},
      "source": [
        "### Model Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4121f2c",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_pipeline_reduced = Pipeline([\n",
        "    ('smote', SMOTE(random_state=42, k_neighbors=1)),\n",
        "    ('logreg', LogisticRegression(class_weight='balanced', max_iter=50000, random_state=42))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de4f131c",
      "metadata": {},
      "source": [
        "#### Cross-Validation Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "445203e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Define cross-validation\n",
        "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=90)\n",
        "\n",
        "# 4. Perform cross-validation\n",
        "cv_results_reduced = cross_validate(\n",
        "    model_pipeline_reduced,\n",
        "    X_reduced,  # Now using reduced feature set!\n",
        "    y,\n",
        "    cv=cv,\n",
        "    scoring=scoring,\n",
        "    return_train_score=False\n",
        ")\n",
        "\n",
        "# 5. Summarize results\n",
        "print(\"\\n\u2705 Cross-Validation Results (Reduced Feature Set):\\n\")\n",
        "\n",
        "for metric in scoring:\n",
        "    print(f\"{metric.capitalize()} (Test Set): {cv_results_reduced[f'test_{metric}']}\")\n",
        "    print(f\"Mean {metric.capitalize()}: {np.mean(cv_results_reduced[f'test_{metric}']):.4f}\")\n",
        "    print(\"-\" * 40)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eaf0ac42",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Overview DataFrame\n",
        "cv_summary_reduced = pd.DataFrame({\n",
        "    metric: [np.mean(cv_results_reduced[f'test_{metric}'])] for metric in scoring\n",
        "})\n",
        "\n",
        "print(\"\\n\u2705 Cross-Validation Metric Summary (Reduced Set, Mean over 5 folds):\\n\")\n",
        "print(cv_summary_reduced)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aaeadb6",
      "metadata": {},
      "source": [
        "### Fitting the Model Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10d6fa03",
      "metadata": {},
      "outputs": [],
      "source": [
        "model_pipeline_reduced.fit(X_reduced, y)\n",
        "\n",
        "coefficients_reduced = model_pipeline_reduced.named_steps['logreg'].coef_[0]\n",
        "features_reduced = X_reduced.columns\n",
        "\n",
        "feature_importances_reduced = pd.DataFrame({\n",
        "    'Feature': features_reduced,\n",
        "    'Coefficient': coefficients_reduced\n",
        "}).sort_values('Coefficient', key=lambda x: abs(x), ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a393321",
      "metadata": {},
      "source": [
        "### Plotting Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c87a9f0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot\n",
        "plt.figure(figsize=(9, 5))\n",
        "plt.barh(feature_importances_reduced['Feature'], feature_importances_reduced['Coefficient'])\n",
        "plt.xlabel('Coefficient')\n",
        "plt.title('Feature Importances (Reduced Feature Set)')\n",
        "plt.axvline(0, color='black', linewidth=0.8)\n",
        "plt.gca().invert_yaxis()\n",
        "plt.grid(axis='x')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0fd1eed7",
      "metadata": {},
      "source": [
        "### Predict Probability of Engagement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62c325e2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Predict probabilities\n",
        "predicted_probs = model_pipeline_reduced.predict_proba(X_reduced)[:, 1]  # Probability of class 1 (Low Bounce)\n",
        "\n",
        "# 3. Attach probabilities to your dataframe\n",
        "attempt2_df_reduced = attempt2_df.copy()  # Original full dataset\n",
        "attempt2_df_reduced = attempt2_df_reduced.loc[X_reduced.index]  # Align to reduced features\n",
        "attempt2_df_reduced['Predicted_Engagement_Prob'] = predicted_probs\n",
        "\n",
        "# 4. View\n",
        "print(\"\\nPredicted Probabilities of Low Bounce (High Engagement):\\n\")\n",
        "attempt2_df_reduced[['Keyword', 'Predicted_Engagement_Prob']].sort_values('Predicted_Engagement_Prob', ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "758e4d3f",
      "metadata": {},
      "source": [
        "### Export to a CSV for Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e57c5a72",
      "metadata": {},
      "outputs": [],
      "source": [
        "### CHANGE THIS TO A DIRECTORY WHERE YOU WANT TO SAVE THE FILE\n",
        "# Save the reduced dataset with predictions\n",
        "attempt2_df_reduced.to_csv('/anonymized_path/sakshikumar/Documents/UCD/04. SP 2025/464 Practicum/KWSM finale/collated_dataset.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32c69c39",
      "metadata": {},
      "source": [
        "-----------"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13e000b8",
      "metadata": {},
      "source": [
        "### Merge Model 1 Results for Final Output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37b7ae28",
      "metadata": {},
      "source": [
        "#### Load Model 1 Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa13e585",
      "metadata": {},
      "outputs": [],
      "source": [
        "### CHANGE THIS TO A DIRECTORY WHERE YOU HAVE SAVED MODEL 1 RESULTS\n",
        "## Load Model 1 results\n",
        "model1_res = pd.read_csv(\"/anonymized_path/sakshikumar/Documents/UCD/04. SP 2025/464 Practicum/KWSM finale/Model1_Table.csv\")\n",
        "model1_res.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46359025",
      "metadata": {},
      "source": [
        "#### Display Model 2 Input Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8d14fae",
      "metadata": {},
      "outputs": [],
      "source": [
        "attempt2_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab9d4c1e",
      "metadata": {},
      "source": [
        "#### Merge the 2 Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08dbee3d",
      "metadata": {},
      "outputs": [],
      "source": [
        "merged_keywords = pd.merge(model1_res, attempt2_df_reduced, on='Keyword', how='inner')\n",
        "print(f\"Merged dataset shape: {merged_keywords.shape}\")\n",
        "merged_keywords.head()  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbd7aa0b",
      "metadata": {},
      "source": [
        "#### Clean Merged Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83a20dde",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean merged dataset\n",
        "drop_cols = ['Commercial_y', 'Transactional_y', 'Position_y', 'KD_y', 'Volume_y']\n",
        "merged_keywords = merged_keywords.drop(columns=drop_cols)\n",
        "merged_keywords.rename(columns={\n",
        "    'Commercial_x': 'Commercial',\n",
        "    'Transactional_x': 'Transactional',\n",
        "    'Position_x': 'Position',\n",
        "    'KD_x': 'KD',\n",
        "    'Volume_x': 'Volume'\n",
        "}, inplace=True)\n",
        "\n",
        "merged_keywords.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "279c0b10",
      "metadata": {},
      "source": [
        "#### Applying Filters to Obtain Final Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eee9a92",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Filter for Commercial or Transactional intent\n",
        "high_intent_keywords = merged_keywords[\n",
        "    (merged_keywords['Commercial'] == 1) | (merged_keywords['Transactional'] == 1)\n",
        "]\n",
        "\n",
        "# 4. Filter for low KD (e.g., KD <= 20)\n",
        "# low_kd_keywords = high_intent_keywords[high_intent_keywords['KD'] <= 20]\n",
        "\n",
        "# 5. Filter for High Predicted Engagment\n",
        "high_engagement_keywords = high_intent_keywords[high_intent_keywords['Predicted_Engagement_Prob'] >= 0.7]\n",
        "\n",
        "# Select relevant columns\n",
        "final_keywords = high_engagement_keywords[['Keyword', 'Commercial', 'Transactional', 'KD', 'Volume', 'Opportunity_Score', 'Position', 'Predicted_Position', 'Predicted_Engagement_Prob']]\n",
        "final_keywords.sort_values(by='Predicted_Position', ascending=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed7555fc",
      "metadata": {},
      "source": [
        "#### Calculating New Opportunity Score and Ordering Final Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98c9c3a2",
      "metadata": {},
      "outputs": [],
      "source": [
        "final_keywords['New_Opportunity_Score'] = (\n",
        "    (final_keywords['Commercial'] + final_keywords['Transactional']) *\n",
        "    final_keywords['Volume'] *\n",
        "    final_keywords['Predicted_Engagement_Prob']\n",
        ") / (\n",
        "    (final_keywords['KD'] + 1) * (final_keywords['Predicted_Position'] + 1)\n",
        ")\n",
        "\n",
        "# Sort by new score\n",
        "final_keywords_sorted = final_keywords.sort_values('New_Opportunity_Score', ascending=False)\n",
        "\n",
        "# View final recommended keywords\n",
        "print(\"\\n\u2705 Final Ranked Keywords based on New Opportunity Score:\\n\")\n",
        "final_keywords_sorted[['Keyword', 'Commercial', 'Transactional', 'KD', 'Volume', 'New_Opportunity_Score', 'Position', 'Predicted_Position', 'Predicted_Engagement_Prob']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cdfb44f",
      "metadata": {},
      "outputs": [],
      "source": [
        "## CHANGE THIS TO A DIRECTORY WHERE YOU WANT TO SAVE THE FINAL KEYWORDS\n",
        "# Save final keywords to CSV\n",
        "final_keywords_sorted.to_csv('/anonymized_path/sakshikumar/Documents/UCD/04. SP 2025/464 Practicum/KWSM finale/final_keywords.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}